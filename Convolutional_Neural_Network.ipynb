{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from constants import FLOAT_DTYPE, INT_DTYPE, EPOCHS\n",
    "from Network import CNN\n",
    "from Layers import BatchNorm, Conv2D, Dropout, Relu, Softmax\n",
    "from dataset import get_2D_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = get_2D_normalised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded vectors\n",
    "num_classes = 10\n",
    "train_labels_enc = np.eye(num_classes)[train_labels].reshape(-1, num_classes)\n",
    "test_labels_enc = np.eye(num_classes)[test_labels].reshape(-1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation sets\n",
    "val_split = 0.2\n",
    "num_examples = train_data.shape[0]\n",
    "val_size = int(val_split * num_examples)\n",
    "train_size = num_examples - val_size\n",
    "\n",
    "x_train = FLOAT_DTYPE(train_data[:train_size])\n",
    "y_train = INT_DTYPE(train_labels_enc[:train_size])\n",
    "x_val = FLOAT_DTYPE(train_data[train_size:])\n",
    "y_val = INT_DTYPE(test_labels_enc[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 32, 32, 3)\n",
    "x_val = x_val.reshape(-1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "model.add(Conv2D(3, 64))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Relu())\n",
    "\n",
    "model.add(Conv2D(3, 128))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Relu())\n",
    "\n",
    "model.add(Conv2D(3, 128))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100 in progress =========================================\n",
      "Epoch 1 Forward Propogation Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [01:59<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 17.2 GiB for an array with shape (40000, 30, 30, 64) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\JioInstitute\\Quarter-4\\ComputerVision\\Assignments\\Neural_Network_Backpropogation\\Convolutional_Neural_Network.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/JioInstitute/Quarter-4/ComputerVision/Assignments/Neural_Network_Backpropogation/Convolutional_Neural_Network.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(x_train, y_train, EPOCHS)\n",
      "File \u001b[1;32md:\\JioInstitute\\Quarter-4\\ComputerVision\\Assignments\\Neural_Network_Backpropogation\\Network\\base.py:140\u001b[0m, in \u001b[0;36mBaseNetwork.train\u001b[1;34m(self, x_train, y_train, epochs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m    137\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m in progress =========================================\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m start_time \u001b[39m=\u001b[39m time()\n\u001b[1;32m--> 140\u001b[0m accuracy, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_batch(i, x_train, y_train)\n\u001b[0;32m    142\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccuracy\u001b[39m.\u001b[39mappend(accuracy)\n\u001b[0;32m    143\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32md:\\JioInstitute\\Quarter-4\\ComputerVision\\Assignments\\Neural_Network_Backpropogation\\Network\\base.py:112\u001b[0m, in \u001b[0;36mBaseNetwork._train_batch\u001b[1;34m(self, epoch, x_batch, y_batch)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mTrain the model using SGD for batch\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Forward Propogation Started\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m yhat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forwardprop(x_batch)\n\u001b[0;32m    113\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Forward Propogation Finished\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Backward Propogation Started\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\JioInstitute\\Quarter-4\\ComputerVision\\Assignments\\Neural_Network_Backpropogation\\Network\\base.py:46\u001b[0m, in \u001b[0;36mBaseNetwork._forwardprop\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     44\u001b[0m     A_prev \u001b[39m=\u001b[39m A_curr\n\u001b[0;32m     45\u001b[0m     layer\u001b[39m.\u001b[39minput \u001b[39m=\u001b[39m A_prev\n\u001b[1;32m---> 46\u001b[0m     A_curr \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward()\n\u001b[0;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m A_curr\n",
      "File \u001b[1;32md:\\JioInstitute\\Quarter-4\\ComputerVision\\Assignments\\Neural_Network_Backpropogation\\Layers\\convolutionlayer.py:115\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mview \u001b[39m=\u001b[39m asStride(mat_pad, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride)\n\u001b[0;32m    114\u001b[0m \u001b[39m# the choice of numpy.einsum is due to reshape of self.view being a copy\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meinsum(\u001b[39m'\u001b[39;49m\u001b[39mlmnijk, jkio -> lmno\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mview,\n\u001b[0;32m    116\u001b[0m                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights, optimize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPE) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias\n\u001b[0;32m    117\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 17.2 GiB for an array with shape (40000, 30, 30, 64) and data type float64"
     ]
    }
   ],
   "source": [
    "model.train(x_train, y_train, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(40000, 1, 1, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "from Utils.conv import asStride\n",
    "\n",
    "_, w, h, c = (40000, 32, 32, 3)\n",
    "size = (32, 32)\n",
    "stride = (1, 1)\n",
    "\n",
    "scale = np.sqrt(2. / (size[0] * size[1] * c))\n",
    "weights = np.random.normal(loc=scale, scale=1., size=(\n",
    "    size[0], size[1], c, 64))\n",
    "\n",
    "bias = np.zeros(shape=(64, ), dtype=FLOAT_DTYPE)\n",
    "\n",
    "kx, ky = size\n",
    "sx, sy = stride\n",
    "input = x_train.astype(FLOAT_DTYPE)\n",
    "\n",
    "# If no pad, every image in the batch is cut\n",
    "mat_pad = input[:, : (w - kx) // sx * sx + kx,\n",
    "                : (h - ky) // sy * sy + ky, ...]\n",
    "\n",
    "print(mat_pad.shape)\n",
    "\n",
    "# Create the view of the array with shape (batch, out_w ,out_h, kx, ky, in_c)\n",
    "view = asStride(mat_pad, size, stride)\n",
    "\n",
    "print(view.shape)\n",
    "\n",
    "# the choice of numpy.einsum is due to reshape of self.view being a copy\n",
    "z = np.einsum('lmnijk, jkio -> lmno', view,\n",
    "              weights, optimize=True) + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 1, 1, 64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
